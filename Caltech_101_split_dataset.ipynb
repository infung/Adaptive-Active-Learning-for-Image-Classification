{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels\n",
    "!pip install imutils\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEED Everything'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pretrainedmodels\n",
    "import numpy as np\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load torch...!!!\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load torchvision ...!!!\n",
    "from torchvision import transforms\n",
    "\n",
    "'''SEED Everything'''\n",
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True # keep True if all the input have same size.\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)\n",
    "'''SEED Everything'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9144/9144 [00:22<00:00, 414.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3060, 64, 64)\n",
      "(3060,)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # GPU\n",
    "epochs = 5 # Number of epochs\n",
    "BS = 16 # Batch size\n",
    "\n",
    "image_paths = list(paths.list_images('./101_ObjectCategories'))\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "unique_labels = {}\n",
    "# omit_labels = ['BACKGROUND_Google', 'brontosaurus','ferry','nautilus','trilobite','buddha','flamingo','octopus','umbrella','butterfly','flamingo_head','okapi','watch','camera','garfield','pagoda','water_lilly','cannon','gerenuk','panda','wheelchair','car_side','gramophone','pigeon','wild_cat','ceiling_fan','grand_piano','pizza','windsor_chair','cellphone','hawksbill','platypus','wrench','chair','headphone','pyramid','yin_yang','chandelier','hedgehog','revolver','cougar_body','helicopter','rhino','binocular','emu','menorah','strawberry','bonsai','euphonium','metronome','sunflower','brain','ewer','minaret','tick']\n",
    "for img_path in tqdm(image_paths):\n",
    "    label = img_path.split(os.path.sep)[-2]\n",
    "#     if label in omit_labels:\n",
    "#         continue\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "    \n",
    "    if label in labels and (unique_labels[label] < 30):\n",
    "        unique_labels[label] += 1\n",
    "        data.append(resized)\n",
    "    elif label not in unique_labels:\n",
    "        unique_labels[label] = 1\n",
    "        data.append(resized)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    labels.append(label)\n",
    "\n",
    "labels_to_int_dict = {}\n",
    "labels_to_int = []\n",
    "next_int = 1\n",
    "\n",
    "for word in labels:\n",
    "    if word not in labels_to_int_dict:\n",
    "        labels_to_int_dict[word] = next_int\n",
    "        next_int += 1\n",
    "    labels_to_int.append(labels_to_int_dict[word])\n",
    "\n",
    "data = np.array(data) / 255.0\n",
    "labels_to_int = np.array(labels_to_int)\n",
    "print(data.shape)\n",
    "print(labels_to_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes: 102\n",
      "[0.67058824 0.6745098  0.68235294 0.68235294 0.68235294 0.68627451\n",
      " 0.69019608 0.69019608 0.68627451 0.68235294 0.69019608 0.69803922\n",
      " 0.70196078 0.69803922 0.69803922 0.70588235 0.70588235 0.69803922\n",
      " 0.70196078 0.70980392 0.70588235 0.70588235 0.71372549 0.72156863\n",
      " 0.72156863 0.71372549 0.73333333 0.76862745 0.79607843 0.81176471\n",
      " 0.75686275 0.26666667 0.24705882 0.50196078 0.55294118 0.2745098\n",
      " 0.09019608 0.08235294 0.61176471 0.73333333 0.71372549 0.71764706\n",
      " 0.71764706 0.71372549 0.71764706 0.71372549 0.70588235 0.70980392\n",
      " 0.70980392 0.70196078 0.69803922 0.69411765 0.69411765 0.69411765\n",
      " 0.69411765 0.69019608 0.69411765 0.69411765 0.69411765 0.68235294\n",
      " 0.67843137 0.67843137 0.67843137 0.6745098 ]\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "labels_to_int = lb.fit_transform(labels_to_int)\n",
    "print(f\"Total Number of Classes: {len(lb.classes_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (1071, 64, 64)\n",
      "x_test examples: (1071, 64, 64)\n",
      "x_val examples: (918, 64, 64)\n",
      "y_train examples: (1071,)\n",
      "y_test examples: (1071,)\n",
      "y_val examples: (918,)\n"
     ]
    }
   ],
   "source": [
    "# divide the data into train, validation, and test set\n",
    "(X, x_val , Y, y_val) = train_test_split(data, labels_to_int, test_size=0.3,  stratify=labels_to_int,random_state=42)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")\n",
    "print(f\"y_train examples: {y_train.shape}\\ny_test examples: {y_test.shape}\\ny_val examples: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (1071, 4096)\n",
      "x_test examples: (1071, 4096)\n",
      "x_val examples: (918, 4096)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_val = x_val.reshape(x_val.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3060, 4096)\n",
      "Number of dimensions after reduction: 237\n",
      "(1071, 237)\n",
      "(1071, 237)\n",
      "(918, 237)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "print(data.shape)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(x_train)\n",
    "\n",
    "# The number of dimensions the training image features should be reduced to, which perserves 95 % of the variances\n",
    "variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_dimensions = np.argmax(variance_ratio >= 0.95) + 1\n",
    "\n",
    "print(\"Number of dimensions after reduction:\", num_dimensions)\n",
    "\n",
    "pca1 = PCA(n_components=num_dimensions)\n",
    "pca1.fit(x_train)\n",
    "reduced_data_train = pca1.transform(x_train)\n",
    "print(reduced_data_train.shape)\n",
    "\n",
    "reduced_data_test = pca1.transform(x_test)\n",
    "print(reduced_data_test.shape)\n",
    "\n",
    "reduced_data_val = pca1.transform(x_val)\n",
    "print(reduced_data_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (1071, 238)\n",
      "x_test examples: (1071, 238)\n",
      "x_val examples: (918, 238)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.column_stack((reduced_data_train, y_train))\n",
    "\n",
    "x_val = np.column_stack((reduced_data_val, y_val))\n",
    "\n",
    "x_test = np.column_stack((reduced_data_test, y_test))\n",
    "\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24556489262371614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "labels_predict = model.predict(x_test)\n",
    "print(accuracy_score(y_test, labels_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "matdata = {\n",
    "    'labelset': x_train,\n",
    "    'unlabelset': x_val,\n",
    "    'testset': x_test\n",
    "}\n",
    "io.savemat('./caltech_101.mat', matdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
