{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretrainedmodels in /Users/infung/anaconda3/lib/python3.11/site-packages (0.7.4)\n",
      "Requirement already satisfied: torch in /Users/infung/anaconda3/lib/python3.11/site-packages (from pretrainedmodels) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/infung/anaconda3/lib/python3.11/site-packages (from pretrainedmodels) (0.16.0)\n",
      "Requirement already satisfied: munch in /Users/infung/anaconda3/lib/python3.11/site-packages (from pretrainedmodels) (4.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/infung/anaconda3/lib/python3.11/site-packages (from pretrainedmodels) (4.65.0)\n",
      "Requirement already satisfied: filelock in /Users/infung/anaconda3/lib/python3.11/site-packages (from torch->pretrainedmodels) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/infung/anaconda3/lib/python3.11/site-packages (from torch->pretrainedmodels) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/infung/anaconda3/lib/python3.11/site-packages (from torch->pretrainedmodels) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/infung/anaconda3/lib/python3.11/site-packages (from torch->pretrainedmodels) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/infung/anaconda3/lib/python3.11/site-packages (from torch->pretrainedmodels) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/infung/anaconda3/lib/python3.11/site-packages (from torch->pretrainedmodels) (2023.4.0)\n",
      "Requirement already satisfied: numpy in /Users/infung/anaconda3/lib/python3.11/site-packages (from torchvision->pretrainedmodels) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/infung/anaconda3/lib/python3.11/site-packages (from torchvision->pretrainedmodels) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/infung/anaconda3/lib/python3.11/site-packages (from torchvision->pretrainedmodels) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/infung/anaconda3/lib/python3.11/site-packages (from jinja2->torch->pretrainedmodels) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/infung/anaconda3/lib/python3.11/site-packages (from requests->torchvision->pretrainedmodels) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/infung/anaconda3/lib/python3.11/site-packages (from requests->torchvision->pretrainedmodels) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/infung/anaconda3/lib/python3.11/site-packages (from requests->torchvision->pretrainedmodels) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/infung/anaconda3/lib/python3.11/site-packages (from requests->torchvision->pretrainedmodels) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/infung/anaconda3/lib/python3.11/site-packages (from sympy->torch->pretrainedmodels) (1.3.0)\n",
      "Requirement already satisfied: imutils in /Users/infung/anaconda3/lib/python3.11/site-packages (0.5.4)\n",
      "Requirement already satisfied: opencv-python in /Users/infung/anaconda3/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/infung/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels\n",
    "!pip install imutils\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEED Everything'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pretrainedmodels\n",
    "import numpy as np\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load torch...!!!\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load torchvision ...!!!\n",
    "from torchvision import transforms\n",
    "\n",
    "'''SEED Everything'''\n",
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True # keep True if all the input have same size.\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)\n",
    "'''SEED Everything'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9144/9144 [00:22<00:00, 398.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3060, 128, 128)\n",
      "(3060,)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # GPU\n",
    "epochs = 5 # Number of epochs\n",
    "BS = 16 # Batch size\n",
    "\n",
    "image_paths = list(paths.list_images('./101_ObjectCategories'))\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "unique_labels = {}\n",
    "for img_path in tqdm(image_paths):\n",
    "    label = img_path.split(os.path.sep)[-2]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(img, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    if label in labels and (unique_labels[label] < 30):\n",
    "        unique_labels[label] += 1\n",
    "        data.append(resized)\n",
    "    elif label not in unique_labels:\n",
    "        unique_labels[label] = 1\n",
    "        data.append(resized)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    labels.append(label)\n",
    "\n",
    "labels_to_int_dict = {}\n",
    "labels_to_int = []\n",
    "next_int = 1\n",
    "\n",
    "for word in labels:\n",
    "    if word not in labels_to_int_dict:\n",
    "        labels_to_int_dict[word] = next_int\n",
    "        next_int += 1\n",
    "    labels_to_int.append(labels_to_int_dict[word])\n",
    "\n",
    "data = np.array(data)\n",
    "data = data.astype(np.float64) \n",
    "labels_to_int = np.array(labels_to_int)\n",
    "print(data.shape)\n",
    "print(labels_to_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes: 102\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "labels_to_int = lb.fit_transform(labels_to_int)\n",
    "print(f\"Total Number of Classes: {len(lb.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3060, 16384)\n",
      "(3060, 549)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "print(data.shape)\n",
    "\n",
    "# pca = PCA()\n",
    "# pca.fit(data)\n",
    "\n",
    "# # The number of dimensions the training image features should be reduced to, which perserves 95 % of the variances\n",
    "# variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "# num_dimensions = np.argmax(variance_ratio >= 0.95) + 1\n",
    "\n",
    "# print(\"Number of dimensions after reduction:\", num_dimensions)\n",
    "\n",
    "num_dimensions = 549\n",
    "pca = PCA(n_components=num_dimensions)\n",
    "pca.fit(data)\n",
    "reduced_data = pca.transform(data)\n",
    "\n",
    "print(reduced_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (918, 549)\n",
      "x_test examples: (918, 549)\n",
      "x_val examples: (1224, 549)\n",
      "y_train examples: (918,)\n",
      "y_test examples: (918,)\n",
      "y_val examples: (1224,)\n"
     ]
    }
   ],
   "source": [
    "# divide the data into train, validation, and test set\n",
    "(X, x_val , Y, y_val) = train_test_split(reduced_data, labels_to_int, test_size=0.4,  stratify=labels_to_int,random_state=42)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")\n",
    "print(f\"y_train examples: {y_train.shape}\\ny_test examples: {y_test.shape}\\ny_val examples: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (918, 550)\n",
      "x_test examples: (918, 550)\n",
      "x_val examples: (1224, 550)\n"
     ]
    }
   ],
   "source": [
    "from scipy import io\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_train = np.column_stack((x_train, y_train))\n",
    "\n",
    "x_val = x_val.reshape(x_val.shape[0], -1)\n",
    "x_val = np.column_stack((x_val, y_val))\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "x_test = np.column_stack((x_test, y_test))\n",
    "\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")\n",
    "\n",
    "matdata = {\n",
    "    'labelset': x_train,\n",
    "    'unlabelset': x_val,\n",
    "    'testset': x_test\n",
    "}\n",
    "io.savemat('./caltech_101.mat', matdata)\n",
    "\n",
    "# # savetxt('labelset.csv', x_train, delimiter=',')\n",
    "# # savetxt('unlabelset.csv', x_val, delimiter=',')\n",
    "# # savetxt('testset.csv', x_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
